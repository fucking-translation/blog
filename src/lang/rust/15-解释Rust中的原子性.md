# 解释 Rust 中的原子性

[原文](https://cfsamsonbooks.gitbook.io/explaining-atomics-in-rust/)

> 当处理原子性以及内存排序选项时理解它们可以帮助我们更好的理解多线程编程以及为什么 Rust 可以帮助我们编写安全高性能的多线程代码。

---

尝试通过阅读随机的文章或者 Rust (或 C++) 中的文档来理解原子性，就像是通过逆向工程`E = MC^2`来学物理一样。

我将会在本文中尽最大的努力来向你我解释这个概念。如果我成功了，比例将会是`WTF?/AHA! < 1`。

---

## 多处理器编程

当我们为多个 CPU 编写代码时，有一些细微的 (subtle) 的事情需要考虑。你将看到，如果编译器或 CPU 认为重排我们编写的代码可以获得更快的执行速度，它们就会这么做。在单线程的程序中，我们不需要考虑什么，但是一旦我们开始编写多线程程序时，编译器重排可能就会给我们带来问题。

然而，虽然编译器的顺序可以通过查看反汇编的代码进行检查，当系统运行在多个 CPU 之上时，事情可能会变得更加复杂。

当线程在不同的 CPU 上运行时，CPU 内部的指令重排可以导致一些难以调试的问题，因为我们大多数时候观察的只是 CPU 重排，执行推断 (speculative)，流水线 (pipeline) 以及缓存的副作用。

我也不认为 CPU 可以提前知道它将如何运行你的代码。

> 原子性解决的问题与内存的加载与存储有关。任何不会操作内存的指令重排都不会对我们关心的内容产生影响。 
>
> 除非另有说明，否则我在这里将使用一个主要参考：[Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 3A](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf)。因此当我说参考了 Intel 开发人员参考手册的某一章节，便指的是这篇文章。

让我们从最底层开始，用适合我们的方式来获取更好的理解。

---

## 强 vs 弱内存排序

首先，我们需要正确的理解一些概念。在处理内存方面，CPU 提供了不同的保证。我们可以将其区分为从弱 (Weak) 到强 (Strong)。但是，这不是一个精确的规范，因此有些模型介于两者之间。

为了抽象这些差异，Rust 有一个[抽象机](http://www.stroustrup.com/abstraction-and-machine.pdf)的概念。它从 C++ 中借用了这个模型。这个抽象机需要一个抽象，它可以针对弱 CPU 和强 CPU (以及介于两者之间的状态)编程。

你可以看到，[C++ 抽象机](https://people.mpi-sws.org/~viktor/papers/cpp2015-invited.pdf)指定了很多访问内存的方式。如果我们在相同语言中针对强弱处理器应该使用相同的语义，则必须使用这些访问内存的方式。

具有强内存模型的 CPU 提供了一些重要的保证，让我们在抽象机中使用的语义不会做任何操作。这一点也不花哨，这仅是对编译器的提示，让其不要对程序员编写的内存操作顺序做任何改变。

然而在使用弱内存模型的系统中，可能需要设置内存栏栅或使用特殊的指令来防止同步问题。根据经验学习这种抽象机的最好方式是使用具有弱有序的 CPU。然而，因为大多数程序员都是在具有强内存模型的 CPU 上编程，因此我们将只需要指出差异就可以理解为什么该语义是它们表现的那样。

目前大多数使用 AMD 或 Intel 处理器的电脑都使用强有序。这就意味着 CPU 会保证不会重排确定的操作顺序。可以在 [Intel 开发人员手册](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf)第 8.2.2 节找到这个保证的相关示例。

> - 读操作不会和其他读操作重新排序。
> - 写操作不会和旧的读操作重新排序。
> - 写内存操作不会和其他(带有异常的)写操作重新排序。

重要的是，它还包含一个不受保证的示例：

> - 读操作可能会与旧的写到不同地址的操作重新排序，但是不会与写到相同地址的操作重新排序。

最后一个示例对于理解后面的`SeqCst`内存排序至关重要，现在这里只是为它做个说明。

现在，在之后的章节，我将会试图理清它们的差异。但是我仍将使用抽象机的弱模型作为解释的基础...

> ⚠️ 我将指出使用这个提示的强有序 CPU 的差异。

---

## CPU 缓存

通常，一个 CPU 有三种级别的缓存：L1，L2，L3。其中 L2 和 L3在各个核心之间共享，L1 是每个核心的缓存。我们的挑战就在这里开始。


L1 缓存使用了某种 [MESI 缓存协议](https://en.wikipedia.org/wiki/MESI_protocol)。名字听起来可能很神秘，但是该协议其实很简单。它是缓存中以下不同状态的首字母缩写 (acronym)：

```console
这些状态适用于 L1 缓存中的每一个缓存行：

(M) Modified - 修改(脏数据)。需要将数据写回主内存。
(E) Exclusive - 只存在 L1 缓存中。不需要被同步(清理)。
(S) Shared - 可能存在其他的缓存中。目前与主内存一起使用。
(I) Invalid - 缓存行是无效的。其他缓存可能会将其修改。
```

> 在 [Intel 开发者手册](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf)的第 11.4 节中，有更多关于缓存状态的描述。

我们可以通过对 CPU 中的每一个缓存行分配一个带有四种状态的枚举，对 L1 缓存进行建模。

> **这听起来是不是很熟悉？**  
> 
> 在 Rust 中我们有两种类型的引用 & 共享引用 (shared references) 和 &mut 独占引用(exclusive references)。
> 
> 如果你不再将它们视为`mutable`和`immutable`，这将对你有很大的帮助。因为并非一直如此。允许内部可变性 (interior mutability) 的原子和类型确实打破了这种心智模型。相反，我们应当将它们视为`exclusive`和`shared`。
> 
> 这确实可以很好的映射到 E 和 S (L1 缓存中可能存在的两种状态数据)。在语言中对其进行建模可以很好的提供一些优化，而其他不存在这些语义的语言却无法做到。
> 
> 在 Rust 中，只有内存是`Exclusive`且默认可以被修改。
>
> 这意味着，只要我们不会打破规则以及可变的`Shared`引用，所有的 Rust 程序可以假设运行在核心上的 L1 缓存是最新的，不需要做任何同步。
>
> 当然，许多程序需要在核心之间`Shared`内存才能工作，但是明确并谨慎这么做可以更好的让代码在多处理器上运行。

---

## 处理器之间的通信

如果我们确实想要访问并改变`Shared`内存，其他的核心是如何知道它们的 L1 缓存是非法的呢？

如果数据存在不同核心的 L1 缓存中(请记住，它处于`Shared`状态)并被修改时，缓存行是无效的。为了通知其他核心它们的缓存数据是无效的，就必须有一些可以在核心之间通信的方式，对吗？

是的，确实如此，但是，很难找到有关确切详细信息的文档。每个核心都有一个我们可以当作邮箱的东西。

该邮箱可以缓存一定数量的消息。每条缓存的消息总是可以避免中断 CPU 并且强制它立即处理发往其他核心的每条消息。

现在，CPU 会在某个时刻检查该邮箱并相应的更新其缓存。

让我们举一个关于标记为`Shared`缓存行的一个示例。

如果 CPU 修改了这个缓存行，它在其他缓存中就会无效。修改数据的核心会向其余的 CPU 发送一条消息。当其他核心检查它们的邮箱时，它们将会发现当前这个缓存行是无效的，然后它的状态会在其他核心中的每个缓冲中相应的更新。

在每个核心上的 L1 缓存接着在主内存(或 L2/L3 缓存)中拉取正确的值，并将它的装态重新设置为`Shared`。

> ⚠️ 在强有序的 CPU 中，这个模型以几种不同的方式进行工作。如果一个核心修改了一个`Shared`缓存行，它将会在这个值实际被修改之前，强制其他核心将相应的缓存行设置为无效。这样的 CPU 有一个 [缓存连贯性 (coherency) 机制](https://en.wikipedia.org/wiki/Cache_coherence)，它可以改变其他核心中缓存的状态。

---

## 内存排序

既然我们对如何设计 CPU 之间的协调有了一些了解，我们可以介绍一些不同的内存排序以及它们的含义。

在 Rust 中，[std::sync::atomic::Ordering](https://doc.rust-lang.org/std/sync/atomic/enum.Ordering.html)代表内存排序，它有 5 个可能的值。

### 心智模型

实际上，由于 Rust 的类型系统，很难对其构建一个心智模型(如：我们无法获取一个`Atomic`的指针)，但是我发现想象一个观察者核心(即一个核心作为观察者)很有用。处于某种原因，这个观察者核心对我们执行原子操作的同一块内存很感兴趣，所以我们将每个模型一分为二：它在运行的核心上看起来怎样以及在观察者核心上看起来怎样。

> 请记住，Rust 从 C++20 中继承了原子的内存模型，C 同样也是从 C++ 中拷贝的。在这些语言中，类型系统不会像在 Safe Rust 中一样约束你，因此使用指针访问`Atomic`更容易。

### Relaxed

**在当前 CPU 中：**

原子性中的 Relaxed 内存排序将会阻止编译器进行指令重排，但是，在弱排序的 CPU 中，它可能会重排所有其他的内存访问顺序。如果你只是将计数器加 1，那当然没有问题，但是如果你使用了一个 flag 实现了自旋锁 (spin-lock)，它可能会给你带来一些问题，因为你不相信 flag 前后的“正常”内存访问已被设置，没有重新排序。

**在观察者 CPU 中：**

编译器和 CPU 都可以自由地对其他任何内存访问进行过重排，除了彼此切换两个`Relaxed`的加载/存储。观察者核心可能观察到操作的顺序与我们代码中编写的顺序不一样。如果我们按此顺序编写它们，它们将始终可以在`Relaxed`操作 B 之前看到`Relaxed`操作 A。

因此，`Relaxed`是可能的内存排序中最弱的。这表明该操作不会与其他 CPU 进行任何的同步。

> 在强有序的 CPU 中，所有的内存操作默认都具有 Acquire/Release 语义。因此，这仅是向编译器提示“这些操作不能在它们之间重新排序”。在强有序的系统中使用这些操作的原因是：它们允许编译器在合适的情况下对所有其他内存访问操作进行重排。
>
> 如果你想知道为什么似乎可以使用`Relaxed`并获得与`Acquire/Release`相同的结果，这就是原因。然而，重要的是尝试理解“抽象机”模型，而不仅仅是依靠在强有序 CPU 中运行实验中所获得的经验。你的代码可能在不同的 CPU 中被中断。
>
> 查看[这篇文章](https://preshing.com/20121019/this-is-why-they-call-it-a-weakly-ordered-cpu/)，它们在强有序和弱有序的 CPU 中运行相同的代码，以了解它们之间的区别。

### Acquire

**在当前 CPU 中：**

在`Acquire`访问操作之后写入的任何内存操作都将保留在该操作之后。这意味着它与`Release`内存排序标志配对，形成了一种“内存三明治”。所有在加载 (load) 和存储 (store) 之间的内存访问操作都将与其他 CPU 进行同步。

在弱有序的系统中，这可能导致在`Acquire`操作之前使用专门的 CPU 指令，它会强制当前的核心处理其邮箱中所有的消息(许多 CPU 都具有序列化及内存排序指令)。很有可能还会实现内存栏栅，以防止 CPU 在`Acquire`加载之前对内存访问操作的顺序进行重排。

> **内存栏栅 (memory fences)**
>
> 由于我们是第一次遇到这个术语，就不要假装所有人都了解它然后将它放过。内存栏栅是个**硬件**概念。它通过强制 CPU 在隔离之前完成对内存的`loads/stores`以防止对 CPU 指令进行重排，因此请确保在对栏栅重新排序之前没有进行任何此类操作，而后才可以对其进行此类操作。
>
> 为了能够区分只读，只写以及读写指令，它们被命名为不同的名称。可以防止读写指令重排的栏栅被称为 full fence。
> 
> 让我们快速浏览 [Intel 开发者手册](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf)中的一个 full fence。(比较简短，我还做了总结)
>
>> 程序的同步也可以通过序列化指令进行(参阅 8.3 节)。这些指令通常用于关键过程或任务边界，以强制完成之前的所有指令，然后跳转到新的代码块或进行上下文切换。和 I/O 指令及锁指令一样，处理器在执行序列化指令之前，**一直等到之前的所有指令都已完成**，并且**所有缓冲的写操作都已耗尽内存**。SFENCE，LFENCE 以及 MFENCE 指令提供了一种性能高效的方式，可确保在在产生弱有序结果及消耗该数据的惯例之间**加载和存储内存排序操作**。
>>
>> MFENCE - **在程序指令流中，序列化在 MFENCE 指令之前发生的所有存储和加载操作**。
>
> 你可以参阅 [Intel 开发者手册](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf)的第 8.2 节及 8.3 节文档，发现 MFENCE 是这样的一个指令。在强有序处理器上不会经常看到这些指令，因为很少需要它们，但在弱有序系统中，它们对于实现抽象机中使用的`Acquire/Release`模型至关重要。

**在观察者 CPU 中：**

因为`Acquire`是一个`load`操作，它不会修改内存，所以不需要对其进行观察。

但是，这里有个注意事项 (caveat)，如果观察者核心本身做了`Acquire`加载操作，它将会看到`Acquire`加载到`Release`存储(包括存储)之间发生的所有内存操作。这意味着需要执行一些全局的同步。让我们在之后介绍到`Release`时再进行讨论。

`Acquire`通常用于写锁，在成功获取锁之后，某些操作需要保留。出于这个确切的原因，`Acquire`仅在加载 (load) 操作时有意义。如果你将`Acquire`作为存储 (store) 操作的内存排序进行传递，Rust 中涉及存储的大多数原子方法都会发生恐慌 (panic)。

> ⚠️ 在强有序的 CPU 中，这将是一个 no-op，因此不会在性能方面产生任何成本。但是，这将阻止编译器对在`Acquire`操作之后发生的所有写入的内存操作进行重新排序，以使它们在`Acquire`操作之前发生。

## Release

**在当前 CPU 中：**

